{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MHNC_TH4_18110103.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbPznqpd5YqM"
      },
      "source": [
        "## Deep Learning - Lab 04\n",
        "\n",
        "* Full name: Äinh Anh Huy\n",
        "* Student ID: 18110103"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqnwm56q5Wie"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Input, Reshape, Dense, Convolution2D, MaxPool2D, BatchNormalization, ReLU, GlobalAveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoQGVMBJ_Z9B"
      },
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        "  def __init__(self, filters_1=64, filters_2=256, kernel_regularizer=None, down_sampling=False):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.filters_1 = filters_1\n",
        "    self.filters_2 = filters_2\n",
        "    self.down_sampling = down_sampling\n",
        "    self.kernel_regularizer = kernel_regularizer\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(ResidualBlock, self).get_config()\n",
        "    config.update({\n",
        "        'n_filters': self.n_filters,\n",
        "        'down_sampling': self.down_sampling,\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.projection_shorcut = (int(input_shape[-1]) != self.filters_2) or self.down_sampling\n",
        "    first_strides = [1,1]\n",
        "    if self.down_sampling:\n",
        "      first_strides = [2,2]\n",
        "\n",
        "    # Convolutional Layer 1\n",
        "    self.main_conv_1 = Convolution2D(filters=self.filters_1,\n",
        "                                     kernel_size=[1,1],\n",
        "                                     strides=first_strides,\n",
        "                                     padding='same',\n",
        "                                     kernel_regularizer=self.kernel_regularizer,\n",
        "                                     activation=None)\n",
        "    self.main_batch_1 = BatchNormalization()\n",
        "    self.main_relu_1 = ReLU()\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    self.main_conv_2 = Convolution2D(filters=self.filters_1,\n",
        "                                     kernel_size=[3,3],\n",
        "                                     strides=[1,1],\n",
        "                                     padding='same',\n",
        "                                     kernel_regularizer=self.kernel_regularizer,\n",
        "                                     activation=None)\n",
        "    self.main_batch_2 = BatchNormalization()\n",
        "    self.main_relu_2 = ReLU()\n",
        "\n",
        "    # Convolutional Layer 3\n",
        "    self.main_conv_3 = Convolution2D(filters=self.filters_2,\n",
        "                                     kernel_size=[1,1],\n",
        "                                     strides=[1,1],\n",
        "                                     padding='same',\n",
        "                                     kernel_regularizer=self.kernel_regularizer,\n",
        "                                     activation=None)\n",
        "    self.main_batch_3 = BatchNormalization()\n",
        "\n",
        "    ## Shortcut connection\n",
        "    if self.projection_shorcut:\n",
        "      self.shortcut_conv = Convolution2D(filters=self.filters_2,\n",
        "                                         kernel_size=[1,1],\n",
        "                                         strides=first_strides,\n",
        "                                         padding='same',\n",
        "                                         kernel_regularizer=self.kernel_regularizer,\n",
        "                                         activation=None)\n",
        "      self.shortcut_batch = BatchNormalization()\n",
        "    \n",
        "    self.main_relu_3 = ReLU()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Convolutional Layer 1\n",
        "    main_conv_1 = self.main_conv_1(inputs)\n",
        "    main_batch_1 = self.main_batch_1(main_conv_1)\n",
        "    main_relu_1 = self.main_relu_1(main_batch_1)\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    main_conv_2 = self.main_conv_2(main_relu_1)\n",
        "    main_batch_2 = self.main_batch_2(main_conv_2)\n",
        "    main_relu_2 = self.main_relu_2(main_batch_2)\n",
        "\n",
        "    # Convolutional Layer 3\n",
        "    main_conv_3 = self.main_conv_3(main_relu_2)\n",
        "    main_batch_3 = self.main_batch_3(main_conv_3)\n",
        "\n",
        "    if self.projection_shorcut:\n",
        "      shortcut_conv = self.shortcut_conv(inputs)\n",
        "      shortcut = self.shortcut_batch(shortcut_conv)\n",
        "    else:\n",
        "      shortcut = inputs\n",
        "\n",
        "    main_add = main_batch_3 + shortcut\n",
        "    main_relu_3 = self.main_relu_3(main_add)\n",
        "\n",
        "    return main_relu_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CWfSwvmgVgO",
        "outputId": "8db6f1c4-aab7-49c5-c271-0c6df409403f"
      },
      "source": [
        "l2_regularizer_rate = 1e-4\n",
        "\n",
        "# Input Layer\n",
        "inputs = Input(shape=(28,28,1))\n",
        "# inputs_reshape = Reshape(target_shape=(28,28,1))(inputs)\n",
        "\n",
        "# Block 1\n",
        "conv_1 = Convolution2D(filters=64,\n",
        "                       kernel_size=[7,7],\n",
        "                       strides=[2,2],\n",
        "                       padding='same',\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate),\n",
        "                       activation=None)(inputs)\n",
        "batch_1 = BatchNormalization()(conv_1)\n",
        "relu_1 = ReLU()(batch_1)\n",
        "maxpool_1 = MaxPool2D(pool_size=[3,3],\n",
        "                      strides=[2,2])(relu_1)\n",
        "\n",
        "# Block 2\n",
        "res2_1 = ResidualBlock(filters_1=64, \n",
        "                       filters_2=256,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(maxpool_1)\n",
        "res2_2 = ResidualBlock(filters_1=64, \n",
        "                       filters_2=256,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res2_1)\n",
        "res2_3 = ResidualBlock(filters_1=64, \n",
        "                       filters_2=256,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res2_2)\n",
        "\n",
        "# Block 3\n",
        "res3_1 = ResidualBlock(filters_1=128, \n",
        "                       filters_2=512,\n",
        "                       down_sampling=True,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res2_3)\n",
        "res3_2 = ResidualBlock(filters_1=128, \n",
        "                       filters_2=512,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res3_1)\n",
        "res3_3 = ResidualBlock(filters_1=128, \n",
        "                       filters_2=512,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res3_2)\n",
        "res3_4 = ResidualBlock(filters_1=128, \n",
        "                       filters_2=512,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res3_3)\n",
        "\n",
        "# Block 4\n",
        "res4_1 = ResidualBlock(filters_1=256, \n",
        "                       filters_2=1024,\n",
        "                       down_sampling=True,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res3_4)\n",
        "res4_2 = ResidualBlock(filters_1=256, \n",
        "                       filters_2=1024,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res4_1)\n",
        "res4_3 = ResidualBlock(filters_1=256, \n",
        "                       filters_2=1024,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res4_2)\n",
        "res4_4 = ResidualBlock(filters_1=256, \n",
        "                       filters_2=1024,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res4_3)\n",
        "res4_5 = ResidualBlock(filters_1=256, \n",
        "                       filters_2=1024,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res4_4)\n",
        "res4_6 = ResidualBlock(filters_1=256, \n",
        "                       filters_2=1024,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res4_5)\n",
        "\n",
        "# Block 5\n",
        "res5_1 = ResidualBlock(filters_1=512, \n",
        "                       filters_2=2048,\n",
        "                       down_sampling=True,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res4_6)\n",
        "res5_2 = ResidualBlock(filters_1=512, \n",
        "                       filters_2=2048,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res5_1)\n",
        "res5_3 = ResidualBlock(filters_1=512, \n",
        "                       filters_2=2048,\n",
        "                       down_sampling=False,\n",
        "                       kernel_regularizer=l2(l2_regularizer_rate))(res5_2)\n",
        "\n",
        "# Block Output\n",
        "average_pool = GlobalAveragePooling2D()(res5_3)\n",
        "softmax = Dense(units=10, activation='softmax')(average_pool)\n",
        "\n",
        "model = keras.models.Model(inputs=inputs, outputs=softmax)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 14, 14, 64)        3200      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "residual_block (ResidualBloc (None, 6, 6, 256)         76928     \n",
            "_________________________________________________________________\n",
            "residual_block_1 (ResidualBl (None, 6, 6, 256)         71552     \n",
            "_________________________________________________________________\n",
            "residual_block_2 (ResidualBl (None, 6, 6, 256)         71552     \n",
            "_________________________________________________________________\n",
            "residual_block_3 (ResidualBl (None, 3, 3, 512)         383232    \n",
            "_________________________________________________________________\n",
            "residual_block_4 (ResidualBl (None, 3, 3, 512)         282368    \n",
            "_________________________________________________________________\n",
            "residual_block_5 (ResidualBl (None, 3, 3, 512)         282368    \n",
            "_________________________________________________________________\n",
            "residual_block_6 (ResidualBl (None, 3, 3, 512)         282368    \n",
            "_________________________________________________________________\n",
            "residual_block_7 (ResidualBl (None, 2, 2, 1024)        1520128   \n",
            "_________________________________________________________________\n",
            "residual_block_8 (ResidualBl (None, 2, 2, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_9 (ResidualBl (None, 2, 2, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_10 (ResidualB (None, 2, 2, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_11 (ResidualB (None, 2, 2, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_12 (ResidualB (None, 2, 2, 1024)        1121792   \n",
            "_________________________________________________________________\n",
            "residual_block_13 (ResidualB (None, 1, 1, 2048)        6054912   \n",
            "_________________________________________________________________\n",
            "residual_block_14 (ResidualB (None, 1, 1, 2048)        4471808   \n",
            "_________________________________________________________________\n",
            "residual_block_15 (ResidualB (None, 1, 1, 2048)        4471808   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,601,930\n",
            "Trainable params: 23,548,810\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPoOVy45nii2",
        "outputId": "cefb92e3-9e8f-4a0c-90f5-f10db651fa5b"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "X_train, X_test = X_train/255.0, X_test/255.0\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
        "\n",
        "print(\"> Shape of training set  : \", X_train.shape)\n",
        "print(\"> Shape of validation set: \", X_valid.shape)\n",
        "print(\"> Shape of testing set   : \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "> Shape of training set  :  (54000, 28, 28)\n",
            "> Shape of validation set:  (6000, 28, 28)\n",
            "> Shape of testing set   :  (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19qSCu8ootMb",
        "outputId": "ae4ea871-affa-4b39-8283-7627da568a00"
      },
      "source": [
        "# init Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, decay=1e-4/50)\n",
        "\n",
        "# compile model\n",
        "model.compile(loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=35,\n",
        "                    steps_per_epoch=X_train.shape[0]//128,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "421/421 [==============================] - 48s 57ms/step - loss: 2.9046 - accuracy: 0.6203 - val_loss: 3.6639 - val_accuracy: 0.3440\n",
            "Epoch 2/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 2.0681 - accuracy: 0.8731 - val_loss: 2.0091 - val_accuracy: 0.8910\n",
            "Epoch 3/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.8655 - accuracy: 0.9351 - val_loss: 1.9399 - val_accuracy: 0.9142\n",
            "Epoch 4/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.7740 - accuracy: 0.9608 - val_loss: 1.8919 - val_accuracy: 0.9333\n",
            "Epoch 5/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.7209 - accuracy: 0.9751 - val_loss: 1.9082 - val_accuracy: 0.9300\n",
            "Epoch 6/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.7006 - accuracy: 0.9778 - val_loss: 1.8683 - val_accuracy: 0.9372\n",
            "Epoch 7/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 1.6778 - accuracy: 0.9817 - val_loss: 1.8284 - val_accuracy: 0.9432\n",
            "Epoch 8/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.6520 - accuracy: 0.9839 - val_loss: 1.8112 - val_accuracy: 0.9485\n",
            "Epoch 9/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 1.6243 - accuracy: 0.9870 - val_loss: 1.7756 - val_accuracy: 0.9495\n",
            "Epoch 10/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.6010 - accuracy: 0.9864 - val_loss: 1.7280 - val_accuracy: 0.9583\n",
            "Epoch 11/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.5693 - accuracy: 0.9890 - val_loss: 1.6956 - val_accuracy: 0.9572\n",
            "Epoch 12/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.5285 - accuracy: 0.9914 - val_loss: 1.6767 - val_accuracy: 0.9590\n",
            "Epoch 13/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.5021 - accuracy: 0.9891 - val_loss: 1.6110 - val_accuracy: 0.9615\n",
            "Epoch 14/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.4522 - accuracy: 0.9914 - val_loss: 1.5971 - val_accuracy: 0.9603\n",
            "Epoch 15/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.4085 - accuracy: 0.9915 - val_loss: 1.5032 - val_accuracy: 0.9677\n",
            "Epoch 16/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 1.3584 - accuracy: 0.9918 - val_loss: 1.4373 - val_accuracy: 0.9680\n",
            "Epoch 17/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 1.2989 - accuracy: 0.9929 - val_loss: 1.3960 - val_accuracy: 0.9673\n",
            "Epoch 18/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 1.2436 - accuracy: 0.9926 - val_loss: 1.3024 - val_accuracy: 0.9723\n",
            "Epoch 19/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.1773 - accuracy: 0.9938 - val_loss: 1.2438 - val_accuracy: 0.9737\n",
            "Epoch 20/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 1.1124 - accuracy: 0.9946 - val_loss: 1.1908 - val_accuracy: 0.9725\n",
            "Epoch 21/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 1.0477 - accuracy: 0.9947 - val_loss: 1.1008 - val_accuracy: 0.9758\n",
            "Epoch 22/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 0.9803 - accuracy: 0.9957 - val_loss: 1.0388 - val_accuracy: 0.9748\n",
            "Epoch 23/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.9201 - accuracy: 0.9946 - val_loss: 0.9826 - val_accuracy: 0.9777\n",
            "Epoch 24/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.8564 - accuracy: 0.9958 - val_loss: 0.9048 - val_accuracy: 0.9802\n",
            "Epoch 25/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.7994 - accuracy: 0.9960 - val_loss: 0.8701 - val_accuracy: 0.9763\n",
            "Epoch 26/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.7503 - accuracy: 0.9948 - val_loss: 0.8186 - val_accuracy: 0.9718\n",
            "Epoch 27/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.6987 - accuracy: 0.9959 - val_loss: 0.7707 - val_accuracy: 0.9770\n",
            "Epoch 28/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 0.6528 - accuracy: 0.9960 - val_loss: 0.6946 - val_accuracy: 0.9828\n",
            "Epoch 29/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.6080 - accuracy: 0.9971 - val_loss: 0.6640 - val_accuracy: 0.9820\n",
            "Epoch 30/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.5712 - accuracy: 0.9964 - val_loss: 0.6443 - val_accuracy: 0.9798\n",
            "Epoch 31/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.5369 - accuracy: 0.9963 - val_loss: 0.5953 - val_accuracy: 0.9822\n",
            "Epoch 32/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.5026 - accuracy: 0.9972 - val_loss: 0.5883 - val_accuracy: 0.9747\n",
            "Epoch 33/35\n",
            "421/421 [==============================] - 22s 53ms/step - loss: 0.4741 - accuracy: 0.9969 - val_loss: 0.5390 - val_accuracy: 0.9810\n",
            "Epoch 34/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.4524 - accuracy: 0.9965 - val_loss: 0.5256 - val_accuracy: 0.9788\n",
            "Epoch 35/35\n",
            "421/421 [==============================] - 22s 52ms/step - loss: 0.4281 - accuracy: 0.9973 - val_loss: 0.4761 - val_accuracy: 0.9862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJGvUw3Ko1XE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9432ff1b-aa2f-4b3f-edc1-cadd40daea3b"
      },
      "source": [
        "evaluation = model.evaluate(X_test, y_test)\n",
        "print(\"Accuracy of model on MNIST dataset: {}, and loss: {}.\".format(evaluation[1], evaluation[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4599 - accuracy: 0.9881\n",
            "Accuracy of model on MNIST dataset: 0.988099992275238, and loss: 0.4598911702632904.\n"
          ]
        }
      ]
    }
  ]
}